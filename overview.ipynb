{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuperSlakh\n",
    "\n",
    "SuperSlakh is a dataset of synthesized MIDI songs for training music tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll download the [Lakh Midi dataset](https://colinraffel.com/projects/lmd/) and some soundfonts. \n",
    "\n",
    "The function downloads every soundfont from [this archive.org](https://archive.org/download/free-soundfonts-sf2-2019-04) list, but feel free to add more to the `soundfonts/` folder\n",
    "\n",
    "In total, this downloads 6 Gb of Midi, and 6.4 Gb of soundfonts\n",
    "\n",
    "I also used:\n",
    "\n",
    "- A couple of [St. GIGA's](http://stgiga.weebly.com/creations.html) soundfonts (the 4gb one is great)\n",
    "- [Tyroland (musical artifacts)](https://musical-artifacts.com/artifacts/1305)\n",
    "- [Phil's Computer Lab](https://www.philscomputerlab.com/general-midi-and-soundfonts.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.download import download_midi_and_soundfonts\n",
    "\n",
    "\n",
    "download_midi_and_soundfonts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Catalog & Split Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make working with the data a bit easier, I'm using a SQLite database to manage Songs, Stems, Kits, and Instruments. This allows for read/write in parallel, relating `songs > stems <-> instruments < kits`, etc.\n",
    "\n",
    "Now we need to read each soundfont file to get the metadata into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for each soundfont, \n",
    "    create a kit\n",
    "    create instrument for each preset\n",
    "\"\"\"\n",
    "import fluidsynth\n",
    "import os\n",
    "from src.db import SQLiteClient\n",
    "soundfont_dir = 'soundfonts/'\n",
    "\n",
    "soundfonts = os.listdir(soundfont_dir)\n",
    "num_presets = 0\n",
    "with SQLiteClient('test-song.db') as client:\n",
    "    fs = fluidsynth.Synth()\n",
    "    fs.start()\n",
    "    for file in soundfonts:\n",
    "        try:\n",
    "            sfid = fs.sfload(os.path.join(soundfont_dir, file))\n",
    "            kit_id = client.insert_kit(file)\n",
    "            for bank in range(128):\n",
    "                for preset_num in range(128):\n",
    "                    name = fs.sfpreset_name(sfid, bank, preset_num)\n",
    "                    if name is not None:\n",
    "                        num_presets += 1\n",
    "                        client.insert_instrument(name, bank, preset_num, file, kit_id)\n",
    "                fs.sfunload(sfid)\n",
    "        except Exception as e:\n",
    "            print('ERROR---', e)\n",
    "        \n",
    "    fs.delete()\n",
    "\n",
    "print(len(soundfonts), num_presets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.db import SQLiteClient\n",
    "\n",
    "with SQLiteClient('test-song.db') as client:\n",
    "    instruments = client.get_all_instruments()\n",
    "    kit_ids = [row['kit_id'] for row in instruments]\n",
    "    print(len(set(kit_ids)), len(instruments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similar for each midi file\n",
    "\n",
    "We'll also do a bit of filtering here, we're only interested in songs that:\n",
    "- are valid / readable\n",
    "- are between >30s and <6min\n",
    "- have a drum track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.midi.intake import extract_midi_metadata\n",
    "import time\n",
    "from concurrent.futures import as_completed\n",
    "import random\n",
    "import sqlite3\n",
    "\"\"\"\n",
    "for each midi file\n",
    "    read w/ pretty_midi\n",
    "    if valid\n",
    "        create song\n",
    "        create stem for each track\n",
    "\"\"\"\n",
    "root = 'midi/'\n",
    "\n",
    "def process_midi_file(midi_path: str):\n",
    "    try:\n",
    "        with SQLiteClient('test-song.db') as client:\n",
    "            if client.does_path_exist(midi_path):\n",
    "                print('noneed')\n",
    "                return\n",
    "            midi_data = extract_midi_metadata(midi_path)\n",
    "            if 30 < midi_data.length < 360 and midi_data.has_drum:\n",
    "                inserted = False\n",
    "                while not inserted:\n",
    "                    try:\n",
    "                        client.insert_song(midi_path, None, midi_data.downbeats, midi_data.beats, midi_data.bpm, [])\n",
    "                        inserted = True\n",
    "                    except sqlite3.OperationalError as e:\n",
    "                        if 'database is locked' in str(e):\n",
    "                            print('locked, waiting')\n",
    "                            time.sleep(1)  # Improved back-off strategy might be needed\n",
    "                        else:\n",
    "                            return\n",
    "        print(f\"Processed {midi_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {midi_path}: {e}\")\n",
    "        return\n",
    "\n",
    "def get_file_list(root):\n",
    "    file_list = []\n",
    "    for subdir in os.listdir(root):\n",
    "        files = os.listdir(os.path.join(root, subdir))\n",
    "        file_list.extend([os.path.join(root, subdir, f) for f in files if f.endswith('.mid')])\n",
    "    random.shuffle(file_list)\n",
    "    return file_list\n",
    "\n",
    "\n",
    "file_list = get_file_list(root)\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "with ProcessPoolExecutor(max_workers=14) as executor:\n",
    "    futures = [executor.submit(process_midi_file, file) for file in file_list]\n",
    "    for future in as_completed(futures):\n",
    "        future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classify Instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The songs denote which instrument should play each track by the preset number (for the most part). \n",
    "\n",
    "However, the soundfont preset numbers determined by whoever made each kit, and while many conform to the GM standard, many do not.\n",
    "\n",
    "So, we need to assign a `gm_class` to each instrument, using its filename, preset name, etc. to match it to the most likely instrument class,  \n",
    "e.g. `E Guitar Cln` is most likely `28, Electric Guitar (clean)`.\n",
    "\n",
    "So, we'll do a first pass to classify all the exact matches, a second pass using string distance (levenshtein) to classify the very similar matches, and finally an LLM pass to classify the rest.\n",
    "\n",
    "Then, we'll do a quick check over the stems, and reassign the preset number of each stem whose name is an exact match for another instrument (default class is 1, Accoustic Grand Piano, and there are many '1's with names like 'Trumpet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classify_inst import predict_gm_class_gemini\n",
    "import pandas as pd\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "\n",
    "inst_class = pd.read_csv('data/midi_instrument.csv')\n",
    "\n",
    "\n",
    "\n",
    "def process_row(row):\n",
    "    subdict = {k: row[k] for k in row.keys() if k not in ['id', 'gm_class']}\n",
    "    try:\n",
    "        if subdict['name'].lower() in inst_class['name'].str.lower().values:\n",
    "            gm_class = inst_class.loc[inst_class['name'].str.lower() == subdict['name'].lower(), 'program'].values[0]\n",
    "        else:\n",
    "            gm_class, name = predict_gm_class_gemini(json.dumps(subdict)).split(',', 1)\n",
    "            gm_name = inst_class.loc[inst_class['program'] == int(gm_class), 'name'].values[0]\n",
    "            print(f\"{subdict['name']} -- {name} -- {gm_name}\")\n",
    "            if not name == gm_name:\n",
    "                gm_class = inst_class.loc[inst_class['name'] == name, 'program'].values[0]\n",
    "        with SQLiteClient('test-song.db') as db:\n",
    "            db.update_inst_gm(row['id'], int(gm_class))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        with SQLiteClient('test-song.db') as db:\n",
    "            db.update_inst_gm(row['id'], -2)\n",
    "\n",
    "with SQLiteClient('test-song.db') as db:\n",
    "    instruments = [dict(row) for row in db.get_all_instruments()]\n",
    "    inst_df = pd.DataFrame(instruments)\n",
    "    print(len(instruments))\n",
    "\n",
    "with Pool(4) as p:\n",
    "    p.map(process_row, [row for _, row in inst_df.iterrows()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, many of the drum instruments are 'Misc Sound Effect Banks', so we'll do a quick listen to the kick, snare, hihat of each to make sure they're valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "with SQLiteClient('test-song.db') as client:\n",
    "    instruments = [dict(row) for row in client.get_all_instruments()]\n",
    "    inst_df = pd.DataFrame(instruments)\n",
    "\n",
    "drum_df = inst_df[inst_df['bank'] > 126]\n",
    "\n",
    "def test_drum_presets(df):\n",
    "    fs = fluidsynth.Synth()\n",
    "    fs.start(driver='alsa')\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['flag'] != 0:\n",
    "            continue\n",
    "        root = 'soundfonts'\n",
    "        sfid = fs.sfload(os.path.join(root, row['sf_path']))\n",
    "        fs.program_select(9, sfid, row['bank'], row['preset'])\n",
    "\n",
    "        beats = [36, 38, 42]  # Kick, Snare, Hi-Hat\n",
    "        for beat in beats:\n",
    "            fs.noteon(9, beat, 100)\n",
    "            time.sleep(0.5)  \n",
    "            fs.noteoff(9, beat)\n",
    "\n",
    "        user_input = input(\"Keep this preset? (y/n): \")\n",
    "        if user_input.lower() == 'n':\n",
    "            df.at[index, 'flag'] = -1\n",
    "        elif user_input.lower() != 'y':\n",
    "            print(\"Stopping.\")\n",
    "            break\n",
    "        else:\n",
    "            df.at[index, 'flag'] = 1\n",
    "\n",
    "        fs.sfunload(sfid, True)\n",
    "\n",
    "    # Cleanup\n",
    "    fs.delete()\n",
    "    return df\n",
    "\n",
    "flag_df = test_drum_presets(drum_df)\n",
    "flag_df.to_csv('flagged_drum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Assign Instruments to Stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first thought here was get all stems & presets of each GM class and assign each preset proportionally (but randomly) to each stem. However, this is super inefficient if you need to render per-song instead of per-preset, as you would need to load a new soundfont for every instrument, rather than doing a quick program change (foreshadowing).\n",
    "\n",
    "So, instead we want to use as few kits per song as possible. The core logic is then:\n",
    "- for each song:\n",
    "    - pick a random kit\n",
    "    - while there are unassigned stems:\n",
    "        - for each stem\n",
    "            - pick an unused preset in kit w/ matching class\n",
    "            - if none, continue\n",
    "        - if there are still unassigned stems, pick a new kit\n",
    "\n",
    "This way, we can minimize the amount of kit-switching required by the renderer. Also, the kits tend to be 'similar in vibe' and by choosing mostly instruments from a single kit, the outputs are more sonically cohesive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.db import SQLiteClient\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "with SQLiteClient() as client:\n",
    "    instruments =[dict(row) for row in client.get_all_instruments()]\n",
    "    inst_df = pd.DataFrame(instruments)\n",
    "\n",
    "    stems =[dict(row) for row in client.get_unassigned_stems()]\n",
    "    stem_df = pd.DataFrame(stems)\n",
    "    stem_df['program'] = stem_df['program'].apply(lambda x: min(x+1, 128))\n",
    "\n",
    "song_ids = (stem_df['song_id'].unique())\n",
    "kit_ids = inst_df['kit_id'].unique()\n",
    "kit_to_num_presets = {}\n",
    "for kit_id in kit_ids:\n",
    "    kit_to_num_presets[kit_id] = len(inst_df[inst_df['kit_id'] == kit_id])\n",
    "\n",
    "# Put X kit_ids where X = num presets in kit\n",
    "scaled_kit_ids = [kit_id for kit_id in kit_ids for _ in range(kit_to_num_presets[kit_id])]\n",
    "\n",
    "def pick_random_kit_id(used_ids):\n",
    "    unused_ids = [id for id in kit_ids if id not in used_ids]\n",
    "    if unused_ids:\n",
    "        return random.choice(unused_ids)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "song_to_stems = {}\n",
    "for song_id in song_ids:\n",
    "    song_to_stems[song_id] = stem_df[stem_df['song_id'] == song_id]\n",
    "\n",
    "kit_to_presets = {}\n",
    "for kit_id in kit_ids:\n",
    "    kit_to_presets[kit_id] = inst_df[inst_df['kit_id'] == kit_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_song_presets(song_id):\n",
    "    stems_for_song = song_to_stems[song_id]\n",
    "    used_ids = []\n",
    "    usable_kits = scaled_kit_ids.copy()\n",
    "    while stems_for_song['inst_id'].isnull().any():\n",
    "        random_kit_id = random.choice(usable_kits)\n",
    "        if random_kit_id is None: # No more kits\n",
    "            break\n",
    "        used_ids.append(random_kit_id)\n",
    "        usable_kits =[kit for kit in usable_kits if kit != random_kit_id]\n",
    "        presets_in_kit = kit_to_presets[random_kit_id]\n",
    "        null_stems =  stems_for_song[stems_for_song['inst_id'].isnull()]\n",
    "        for _index, stem in null_stems.iterrows():\n",
    "            usable_presets = presets_in_kit[~presets_in_kit['id'].isin(stems_for_song['inst_id'])]\n",
    "            if stem['is_drum']:\n",
    "                suitable_presets = usable_presets[usable_presets['is_drum'] == 1]\n",
    "            else:\n",
    "                suitable_presets = usable_presets[usable_presets['gm_class'] == stem['program']]\n",
    "            if not suitable_presets.empty:\n",
    "                chosen_preset = suitable_presets.sample(1)\n",
    "                stems_for_song.loc[stems_for_song['id'] == stem['id'], 'inst_id'] = chosen_preset['id'].values[0]\n",
    "\n",
    "    if len(used_ids) > 0:\n",
    "        print(f'NUM KITS = {len(used_ids)}')\n",
    "        stem_inst_list = stems_for_song[['id', 'inst_id']].to_dict('records')\n",
    "        with SQLiteClient() as client:\n",
    "            client.update_stem_inst_ids(stem_inst_list)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "with Pool(processes=12) as p:\n",
    "    p.map(assign_song_presets, song_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Render Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a perfect world, we would simply load each kit, render every stem using a preset from that kit, and then mix the stems into the full songs when you're done. This parallelizes nicely per-preset and is the best-case scenario in terms of io overhead.\n",
    "\n",
    "However, 1.1M ~2:00 Flacs at 22kHz, is ~5.5Tb, and I don't have that kinda room.\n",
    "\n",
    "So, we need to instead:\n",
    "- Render each stem in a song\n",
    "- Mix the full song\n",
    "- Delete the stems\n",
    "\n",
    "Which means we need to parallelize per-song instead, so we can delete stems as we go.\n",
    "\n",
    "This is a loooot more inefficient, as we need to load/unload a few kits per song, but it will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import pretty_midi\n",
    "import shutil\n",
    "from src.audio.render import make_synth, fluidsynthesize, save_audio, mix_audios\n",
    "from src.db import SQLiteClient\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "def render_stem(stem, synthesizer, sfid, tracknum):\n",
    "    output_path = stem['midi_filepath'].replace('/midi/', '/audio/').replace('.mid', '.flac')\n",
    "    if os.path.isfile(output_path):\n",
    "        print('stem -- '+stem['name'])\n",
    "        return output_path\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    inst = pretty_midi.PrettyMIDI(stem['midi_filepath']).instruments[0]\n",
    "    audio = fluidsynthesize(inst, fs=SAMPLE_RATE, synthesizer=synthesizer, sfid=sfid, channel=tracknum)\n",
    "    save_audio(audio, output_path, normalize=True, sr=SAMPLE_RATE)\n",
    "    print('stem -- '+stem['name'])\n",
    "    return output_path\n",
    "\n",
    "def render_song(song_id):\n",
    "    with SQLiteClient('data/song.db') as client:\n",
    "        stems_and_instruments = client.get_stems_and_instruments(song_id)\n",
    "    stems_and_instruments.sort(key=lambda elem: elem[1]['kit_id'])\n",
    "    stem_paths = []\n",
    "    current_sf_path = stems_and_instruments[0][1]['sf_path']\n",
    "    synth, sfid = make_synth(current_sf_path, sr=SAMPLE_RATE)\n",
    "    for (stem, instrument) in stems_and_instruments:\n",
    "        if stem['audio_filepath'] is not None:\n",
    "            stem_paths.append(stem['audio_filepath'])\n",
    "            continue\n",
    "        if instrument['sf_path'] != current_sf_path:\n",
    "            synth.delete()\n",
    "            del synth\n",
    "            current_sf_path = instrument['sf_path']\n",
    "            synth, sfid = make_synth(current_sf_path)\n",
    "        tracknum = 9 if stem['is_drum'] else 0\n",
    "        synth.program_select(tracknum, sfid, instrument['bank'], instrument['preset'])\n",
    "        output_path = render_stem(stem, synth, sfid, tracknum)\n",
    "        stem_paths.append(output_path)\n",
    "    output_path = os.path.join(stem_paths[0].split('instruments')[0], 'full.flac')\n",
    "    mix_audios(stem_paths, output_path)\n",
    "    print('mixed', output_path)\n",
    "    shutil.rmtree(os.path.join(os.path.dirname(output_path), 'instruments'), ignore_errors=True)\n",
    "    with SQLiteClient('data/song.db') as client:\n",
    "        client.update_song_audio_filepath(song_id, output_path)\n",
    "\n",
    "\n",
    "with SQLiteClient('data/song.db') as client:\n",
    "    song_ids = [song['id'] for song in client.get_unrendered_song_ids()]\n",
    "print(len(song_ids))\n",
    "with multiprocessing.Pool(8) as p:\n",
    "    p.map(render_song, song_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see `extract_features.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoawq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
